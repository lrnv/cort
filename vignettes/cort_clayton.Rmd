---
title: "Cort & CortForest Example on clayton-based simulation"
bibliography: ../inst/REFERENCES.bib
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Cort & CortForest Example on clayton-based simulation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



```{r setup, include = FALSE}
library(cort)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```


First, let's create and plot the dataset we will work with. For that, we'll use the gamma frailty model for the Clayton copula (but it'll work for any other completely monotonous archimedean generator), as it is done in the `copula` package, see [there](https://github.com/cran/copula/blob/6e0a5f0332776c24b2f53a81b11a8c66cc3f996d/R/claytonCopula.R#L82)

```{r clayton-frailty-model}
psi <- function(t,alpha) (1 + sign(alpha)*t) ^ (-1/alpha) # generator
rClayton <- function(n,dim,alpha){
  val <- matrix(runif(n * dim), nrow = n)
  gam <- rgamma(n, shape = 1/alpha, rate = 1)
  gam <- matrix(gam, nrow = n, ncol = dim)
  psi(- log(val) / gam,alpha)
}
```

We can now simulate our dataset and visualise it. Note that, for reproducibility reasons, we set the random number generator.


```{r dataset} 
if(as.numeric(version$minor)<6){
  # the way of specifying the random number generation changed. 
  set.seed(12,kind = "Mersenne-Twister",normal.kind = "Inversion")
} else {
  set.seed(12,kind = "Mersenne-Twister",normal.kind = "Inversion",sample.kind = "Rejection")
}


n = 200 # taken small to reduce runtime of the vignette.
d = 4
n_trees = 2 # taken small to reduce runtime of the vignette.
number_max_dim_tree = 4
number_max_dim_forest = 2 # taken small to reduce runtime of the vignette.

data <- matrix(nrow=n,ncol=d)
data[,c(1,4,3)] = rClayton(n=n,dim=d-1,alpha=7)
data[,2] = runif(n)
data[,3] <- 1 - data[,3]


pairs(data,cex=0.6)
  
```

Now that we have our dataset, we could for example run a Cort model on it. Note that the verbosity level is quite progressive. We will here put it on 4 to have debug-level info to see what's the algorithm is doing, without having the `nloptr::slsqp` routine outputs.

```{r run_cort} 
(model = Cort(data,verbose_lvl=4,number_max_dim = number_max_dim_tree,p_value_for_dim_red = 0.75))
```



Let's visualise it : 


```{r simulation}
pairs(model)

```




We see that there are some noise with point were there should not be. We could use bagging to try to remove these : 


```{r run_cortforest} 
(bagged_model = CortForest(data,verbose_lvl = 2,n_trees=n_trees,number_max_dim=number_max_dim_forest))
```



The same plot is avaliable for the forest : 

```{r print_cortforest} 
pairs(bagged_model)
```

























